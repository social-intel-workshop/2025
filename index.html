<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>HAI 2025: Workshop on Socially Aware and Cooperative Intelligent Systems</title>
    <link rel="icon" type="image/x-icon" href="images/favicon.ico">
    <link rel="stylesheet" type="text/css"
        href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="css/main.css">
</head>

<body>
    <!--div id="year-header">
        <ul>
            <li><a href="/2025/">2025</a></li>
        </ul>
    </div-->
    <nav class="navbar navbar-expand-lg navbar-light bg-light sticky-top shadow">
        <!-- <div class="navbar-title"><a href="#">ICRA 2025</a></div> -->
        <a class="navbar-title d-none d-md-block" href="#">
            <img src="images/conference_logo.png" height="60">
        </a>
        <div class="container">
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse"
                data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
                aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse flex-grow-0" id="navbarSupportedContent">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="#">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#submissions">Call for Papers</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#review">Review Timeline</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#schedule">Program</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#opening">Opening</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#speakers">Speakers</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#motivation">Motivation</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#organizers">Organizers</a>
                    </li>
                </ul>
            </div>
        </div>
        <a class="navbar-right-log d-none d-xl-block" href="https://www.jp.honda-ri.com/en/" target="_blank">
            <img src="images/hrijp_log.png" width="140" height="50">
        </a>
    </nav>
    <div class="container" style="max-width: 960px; margin-top: 120px;">
        <div class="jumbotron">
            <h1 class="anchor">Workshop on Socially Aware and Cooperative Intelligent Systems</h1>
            <div class="row">
                <div class="col-lg-6 col-xs-9">
                    <img src="images/banner_1.png" class="d-none d-lg-block"
                        style="width:95%; margin-top: 20px; margin-left: 20px; max-height: 200px;" alt="banner_1">
                    <!--img src="images/banner.png" class="d-none d-md-block d-lg-none d-xl-none"
                        style="margin-left: 20px; width: 95%;"-->
                    <div class="banner-info  shadow">
                        <div class="info-entry">
                            <div class="row">
                                <div class="col-md-1" style="margin-right: 8px;">
                                    <i class="fa fa-location-dot" style="font-size: 2.7rem; margin-top: 10px;"></i>
                                </div>
                                <div class="col-md-9" style="margin-top: auto; margin-bottom: auto;">
                                    Keio University Hiyoshi Campus in Yokohama, Japan
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6 info-entry">
                                <i class="fa fa-calendar">&nbsp;</i>
                                Nov 10th
                            </div>
                            <!--div class="col-md-6 info-entry">
                                <i class="fa fa-clock">&nbsp;</i>
                                08:30 to 12:30
                            </div-->
                        </div>
                    </div>
                </div>
                <div class="col-lg-6">
                    <img src="images/banner_2.png" class="d-none d-lg-block" alt="banner_2">
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="topics"></a>
                <h2 class="h1-bullet">About the Workshop</h2>
            </div>
        </div>
        <div class="row mb-4">
            <div class="col-xs-12">
                <p style="text-indent: 50px;">This workshop proposal focuses on realizing socially
                    aware systems in the wild via cooperative intelligence by keeping humans-in-the-loop. Specifically,
                    this workshop is dedicated to discussing computational methods for sensing and recognition of
                    nonverbal cues and internal states in the wild to realize cooperative intelligence between humans
                    and intelligent systems, including learning and behavior generation complying to the social norm,
                    and other relevant technologies like social interaction datasets.
                </p>
                <p style="text-indent: 50px;">One of the main considerations to achieve cooperative intelligence between
                    humans and intelligent systems is to enable everyone and everything to know each other well, like
                    how humans can trust or infer the implicit internal states like intention, emotion, and cognitive
                    states of each other. The importance of empathy to facilitate human-robot interaction has been
                    highlighted in previous studies. However, it is difficult for intelligent systems to estimate the
                    internal states of humans because they are dependent on the complex social dynamics and environment
                    contexts. This requires intelligent systems to be capable of sensing the multi-modal inputs,
                    reasoning the underlying abstract knowledge, and generating the corresponding responses to
                    collaborate and interact with humans. There are many studies on estimating internal states of humans
                    through measurements of wearables and non-invasive sensors [10, 24], but it would be difficult to
                    implement these solutions in the wild because of the additional sensors to be worn by humans. It
                    remains an open question for intelligent systems to sense and recognize nonverbal cues and reason
                    the rich underlying internal states of humans in the wild and noisy environments. The scope of this
                    workshop includes but not limited to the following:
                </p>
                <ul class="topic-list">
                    <li>Human internal state inference, e.g., cognitive, emotional</li>
                    <li>Recognition of nonverbal cues, e.g., gaze, gesture.</li>
                    <li>Multi-modal sensing fusion for scene perception.</li>
                    <li>Learning algorithms</li>
                    <li>Generative and adversarial algorithms.</li>
                    <li>Empathetic interaction between humansintelligent systems.</li>
                    <li>Robust sensing of facial and body key points.</li>
                    <li>Personalization and trust of intelligent systems</li>
                    <li>Applications of cooperative intelligence in the wild.</li>
                </ul>
                <p class="mb-0"><b>Keywords:</b> "Socially aware AI, cooperative intelligence, group interaction, social
                    norm, nonverbal cues"
                </p>
                <!--p class="mb-0"><b>Secondary subject:</b> "Human-Robot cooperative intelligence", "Nonverbal cues
                    recognition from audiovisual", "Human internal state inference from multi-modality", "Vision
                    applications and systems", "Human-Object interaction and scene understanding"
                </p-->
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="news"></a>
                <h2 class="h1-bullet">News updates</h2>
            </div>
        </div>

        <div class="col-xs-12">
            <div class="news-table">
                <table class="table">
                    <tbody>
                        <tr>
                            <td>June 21th</td>
                            <td>Workshop webpage was launched.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="submissions"></a>
                <h2 class="h1-bullet">Call for Papers</h2>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="review"></a>
                <h4 class="sub-header">Submission Guidelines</h4>
            </div>
        </div>
        <div class="col-xs-12 content">
            <p>We invite authors to submit unpublished papers (2-4 pages excluding references) to our workshop, to be
                presented at a workshop session upon acceptance.
                Submissions will undergo a peer-review process by the workshop's program committee and accepted papers
                will be invited
                to present their works at the workshop (<a href="#presentation">see presentation format</a>). </p>
        </div>

        <div class="row" style="margin-bottom: 10px;">
            <div class="col-md-1"></div>
            <div class="col-md-1 d-none d-md-block">
                <i class="fa-solid fa-quote-left awards-quote"></i>
            </div>
            <div class="col-md-8" style="text-align: center;">
                <b>We are pleased to announce that award will be given to the best paper accepted by this workshop.</b>
            </div>
            <div class="col-md-1 d-none d-md-block">
                <i class="fa-solid fa-quote-right awards-quote"></i>
            </div>
            <div class="col-md-1"></div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="review"></a>
                <h4 class="sub-header">Important Dates</h4>
            </div>
        </div>
        <div class="row mb-4">
            <div class="col-xs-12">
                <ul class="timeline">
                    <li>
                        <span class="date-label">June 20, 2025</span>
                        <p>Notification of workshop acceptance</p>
                    </li>
                    <li>
                        <span class="date-label">June 21, 2025</span>
                        <p>Workshop web page open</p>
                    </li>
                    <li>
                        <span class="date-label">Aug 7, 2025</span>
                        <p>HAI2025 final decisions to authors</p>
                    </li>
                    <li>
                        <span class="date-label"><s>Sep 8</s> Sep 29, 2025</span>
                        <p><span style="color: red;">FINAL EXTENSION!</span> : Workshop paper submission deadline</p>
                    </li>
                    <li>
                        <span class="date-label"><s>Oct 1</s> Oct 14, 2025</span>
                        <p>Workshop paper reviews deadline</p>
                    </li>
                    <li>
                        <span class="date-label"><s>Oct 10</s> Oct 17, 2025</span>
                        <p>Notification to authors</p>
                    </li>
                    <li>
                        <span class="date-label">Oct 31, 2025</span>
                        <p>Camera-ready deadline</p>
                    </li>
                    <li>
                        <span class="date-label">Nov 10, 2025</span>
                        <p>Workshop date</p>
                    </li>
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="review"></a>
                <h4 class="sub-header">Submission Instructions</h4>
            </div>
        </div>
        <div class="col-xs-12" style="margin-bottom: 20px">
            Please use the IEEE conferences paper format to write your manuscript.
            <ul>
                <li>LaTex and MS Word template: <a target="_blank"
                        href="https://www.ieee.org/conferences/publishing/templates.html">https://www.ieee.org/conferences/publishing/templates.html</a>
                </li>
            </ul>
            Please submit your paper electronically through the workshop's EasyChair submission system.
            <ul>
                <li>Link to EasyChair submission system:
                    <a target="_blank"
                        href="https://easychair.org/my/conference?conf=hai2025">https://easychair.org/my/conference?conf=hai2025</a>
                </li>
            </ul>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="presentation"></a>
                <h4 class="sub-header">Presentation Format</h4>
            </div>
        </div>
        <div class="col-xs-12">
            Accepted papers should be presented in three-way presentation approach to foster active participation
            <ul class="topic-list">
                <li>Spotlight talks (8 mins talk, Q&A in the poster session) </li>
                <li>In-person A0 posters for in-depth discussions</li>
                <li>Short pre-recorded videos (about 2 minutes) to be uploaded on the workshop webpage</li>
            </ul>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="pub_format"></a>
                <h4 class="sub-header">Publication Format</h4>
            </div>
        </div>
        <div class="col-xs-12">
            Authors are recommended to archive their papers and inform workshop organizers once this procedure is
            completed. Accepted papers which have been archived will be hosted on the workshop webpage. <br>
            <ul>
                <li>Link to arXiv: <a href="https://info.arxiv.org/help/submit/index.html" target="_blank">
                        https://info.arxiv.org/help/submit/index.html</a>
                </li>
            </ul>
            Extensions of the papers presented at this workshop will be invited to submit to a special issue journal
            to-be-announced at a later date.
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="schedule"></a>
                <h2 class="h1-bullet">Program</h2>
            </div>
        </div>
        <div class="row mb-4">
            <div class="col-xs-12">
                <p>We plan a full-day event for 8 hours, including oral and poster presentations of accepted/invited
                    papers,
                    talks by FOUR invited speakers, TWO interactive sessions including a demonstration and a forum
                    discussion. For participants who could not attend in person, we will disseminate the papers and
                    pre-recorded videos on our workshop page, which also consists of a comment section for Q&A.</p>
                <ul class="schelude">
                    <li>
                        <span class="time-bg">08:30</span>
                        <span class="ribbon">08:33</span>
                        <span class="schelude-item-content">Welcome</span>
                    </li>
                    <li>
                        <span class="time-bg">08:33</span>
                        <span class="ribbon">09:18</span>
                        <span class="schelude-item-content"><a href="#talk1">Invited Talk I: Tim Schrills</a></span>
                    </li>
                    <li>
                        <span class="time-bg">09:18</span>
                        <span class="ribbon">09:33</span>
                        <span class="schelude-item-content"><a href="#opening">Opening remarks: HRI-JP President Satoshi
                                Shigemi</a></span>
                    </li>
                    <li>
                        <span class="time-bg">09:33</span>
                        <span class="ribbon">10:21</span>
                        <span class="schelude-item-content"><a href="#flash-talks">Flash talks I: 6 papers</a> (8
                            mins each)</span>
                    </li>
                    <li>
                        <span class="time-bg">10:21</span>
                        <span class="ribbon">10:55</span>
                        <span class="schelude-item-content">Cofee break and poster session I (34
                            mins)</span>
                    </li>
                    <li>
                        <span class="time-bg">10:55</span>
                        <span class="ribbon">11:40</span>
                        <span class="schelude-item-content"><a href="#talk2">Invited Talk II: Martina Mara</a></span>
                    </li>
                    <li>
                        <span class="time-bg">11:40</span>
                        <span class="ribbon">12:30</span>
                        <span class="schelude-item-content">Forum (50 mins)</span>
                    </li>
                    <li>
                        <span class="time-bg">13:30</span>
                        <span class="ribbon">14:15</span>
                        <span class="schelude-item-content"><a href="#talk3">Invited Talk III: Kazuhiro
                                Nakadai</a></span>
                    </li>
                    <li>
                        <span class="time-bg">14:15</span>
                        <span class="ribbon">15:03</span>
                        <span class="schelude-item-content"><a href="#flash-talks">Flash talks II: 6 papers</a> (8
                            mins each)</span>
                    </li>
                    <li>
                        <span class="time-bg">15:03</span>
                        <span class="ribbon">15:37</span>
                        <span class="schelude-item-content">Coffee break and poster session II (34 mins)</span>
                    </li>
                    <li>
                        <span class="time-bg">15:37</span>
                        <span class="ribbon">16:35</span>
                        <span class="schelude-item-content">DEMO: Group interaction with an agent (58 mins)</span>
                    </li>
                    <li>
                        <span class="time-bg">16:35</span>
                        <span class="ribbon">17:20</span>
                        <span class="schelude-item-content"><a href="#talk4">Invited Talk IV: Mayu Koike</a></span>
                    </li>
                    <li>
                        <span class="time-bg">17:20</span>
                        <span class="ribbon">17:30</span>
                        <span class="schelude-item-content">Closing and awards ceremony (10 mins)</span>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="opening"></a>
                <h2 class="h1-bullet">Opening Speech</h2>
            </div>
        </div>
        <div class="row mb-4 speaker-row">
            <div class="row mb-4">
                <div class="col-xl-3 mb-4">
                    <img src="images/opening_speech.jpg" class="img-speaker shadow">
                </div>
                <div class="col-xl-9 mb-4">
                    <a class="anchor"></a>
                    <h3>Co-Existence with Intelligent Machines</h3>
                    <div><span>Satoshi Shigemi, </span> Honda Research Institute Japan, Japan.</div>
                    <div>Link to website: <a
                            href="http://www.jp.honda-ri.com/en/about/">http://www.jp.honda-ri.com/en/about/</a>
                    </div>
                    <div class="speaker-content">
                        <b>Abstract</b>
                        <p>At the Honda Research Institute Japan, we are conducting research on collaborative
                            intelligence, human understanding, and robot systems. In recent years, generative AI has
                            emerged, and AI technology is becoming more familiar in people's lives. For people and
                            machines to coexist 24 hours a day, 365 days a year, it is essential for intelligent machine
                            systems to understand people's feelings and act accordingly. To achieve this, we focus on
                            human social activities, and our research targets are interactions between individuals,
                            groups, and communities. We aim to advance people's happiness by helping them become the way
                            they ought to be and enhancing their fulfillment. Here, we will introduce the research
                            technologies at the Honda Research Institute to make people happy.</p>
                        <b>Biography</b>
                        <p>Satoshi Shigemi is the President of Honda Research Institute Japan.
                            Since 1987, he has been conducting research on robots and control systems at Honda R&D Co.
                            In 2000, he was
                            the Senior Chief Engineer and project lead for the research and development of ASIMO,
                            the humanoid robot. He then developed a high-altitude survey robot for the Fukushima
                            Daiichi Nuclear Power Plant. He has published many papers about human-robot interaction.</p>
                    </div>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="speakers"></a>
                <h2 class="h1-bullet">Invited Speakers</h2>
            </div>
        </div>
        <div class="row mb-4 speaker-row">
            <div class="col-xs-12">
                <p>
                    We have confirmed the attendance of FOUR speakers:
                </p>
            </div>
            <div class="row mb-4">
                <div class="col-xl-3 mb-4" id="talk1">
                    <img src="images/speaker_1.jpg" class="img-speaker shadow" alt="img">
                </div>
                <div class="col-xl-9 mb-4">
                    <h4>Invited Talk I</h4>
                    <h3>Constructing Human-Aware AI for Integrated Information processing</h3>
                    <div><span>Tim Schrills, </span> University of Lübeck, Germany.</div>
                    <div>Link to website:
                        <a
                            href="https://www.imis.uni-luebeck.de/de/institut/team/tim-schrills">https://www.imis.uni-luebeck.de/de/institut/team/tim-schrills</a>
                    </div>
                    <div class="speaker-content">
                        <b>Abstract</b>
                        <p>Humans and agents increasingly process information in a task simultaneously and clear
                            distinction of roles and sequencing in processes declines. It therefore makes sense to model
                            both partners within a shared information-processing loop. Based on the cybernetic control
                            loop as a model for understanding both action regulation and information processing, this
                            talk will present an Integrated Information Processing (IIP) model that conceptualizes
                            humans, machines, and their joint activity as coupled control loops and uses a unified
                            modeling language for human and artificial agents. For the field of Human–Agent Interaction
                            to move forward, theoretical work that links psychological mechanisms to interface design is
                            needed. Especially in the discussion of agents being ‘aware’ of each other, theoretical
                            models that define, what awareness should include and how states of a partner can be
                            modelled, are of utmost importance. To describe which effects an aware interaction may
                            yield, this talk introduces the IIP model’s three integration qualities—input adequacy,
                            reference consonance, and output operativity—as characteristics of efficacy within a shared
                            task that shape benchmarks of human-centeredness such as transparency and controllability.
                            The talk will give examples of qualities exhibited by optimal coupling of artificial and
                            human intelligence and will discuss strategies in development, design, and evaluation to
                            address sharpness in such tasks. Reflecting the workshops core theme, this talk will discuss
                            what the integration of information processing has to do with awareness and how mutually
                            aware regulation of actions and information may lead to practical criteria for designing and
                            evaluating user interfaces.
                        </p>
                        <b>Biography</b>
                        <p>
                            Tim Schrills is a postdoctoral researcher at the University of Lübeck, Germany. He holds a
                            PhD in Psychology and focuses on human-centered AI, especially explainable AI (XAI) and the
                            cognitive processes that underlie human–AI collaboration. His work develops
                            automation-related constructs and measurements, including instruments for
                            information-processing awareness and cooperativity. Tim’s research examines cognition in
                            human–AI teams, the integration of information-processing capabilities across humans and
                            machines, and the psychological implications for basic needs such as autonomy and
                            competence—informing the design and evaluation of trustworthy, cooperative intelligent
                            systems.
                        </p>
                    </div>
                </div>
            </div>
            <div class="row mb-4">
                <div class="col-xl-3 mb-4" id="talk2">
                    <img src="images/speaker_2.jpg" class="img-speaker shadow" alt="img">
                </div>
                <div class="col-xl-9 mb-4">
                    <h4>Invited Talk II</h4>
                    <h3>Is This a Person Speaking? Unintended Side Effects of Simulated Humanness in Conversational AI
                    </h3>
                    <div><span>Martina Mara, </span> Johannes Kepler Universität Linz, Austria.</div>
                    <div>Link to website: <a
                            href="https://www.jku.at/en/lit-robopsychology-lab/about-us/team/martina-mara/">https://www.jku.at/en/lit-robopsychology-lab/about-us/team/martina-mara/</a>
                    </div>
                    <div class="speaker-content">
                        <b>Abstract</b>
                        <p>
                            The use of conversational AI, such as ChatGPT or DeepSeek, is rising rapidly across many
                            personal and professional settings. These AI models not only enable natural-language
                            interactions but are also increasingly equipped with realistic synthetic voices and other
                            human-like cues that mimic interpersonal communication. Research, including recent studies
                            from Prof. Mara’s Robopsychology Lab, shows that many people readily anthropomorphize AI
                            language models, attributing emotionality, personality, and intentionality to them. While
                            anthropomorphism can help reduce complexity and satisfy the human need for social
                            relatedness, it may also raise concerns. Studies suggest that individuals who more strongly
                            anthropomorphize AI are more likely to endorse granting such systems rights and to judge
                            AI-generated recommendations as more competent and trustworthy, thereby increasing the risk
                            of over-reliance on potentially flawed outputs. Although anthropomorphism of non-human
                            entities is very widespread, it varies with individual and contextual factors. Findings from
                            the Robopsychology Lab indicate that people who feel lonely or have limited AI literacy can
                            be especially prone to anthropomorphism. This talk will examine the psychological mechanisms
                            underlying AI anthropomorphism, its implications for both human-AI and human-human
                            interaction, and practical strategies for de-anthropomorphizing and improving AI literacy in
                            an increasingly AI-integrated world.
                        </p>
                        <b>Biography</b>
                        <p>
                            Martina Mara is a Full Professor of Psychology of Artificial Intelligence & Robotics and
                            Head of the Robopsychology Lab at Johannes Kepler University Linz, Austria. She earned her
                            PhD in Psychology from the University of Koblenz-Landau (2014), focusing on user acceptance
                            of highly human-like robots, and received her habilitation (venia docendi) from the
                            University of Nuremberg (2022). Trained as an empirical psychologist with an
                            interdisciplinary outlook, her research examines how people perceive, trust, and collaborate
                            with intelligent systems—and how system design can foster human autonomy, creativity, and
                            well-being.
                            Before joining JKU in 2018, Martina spent many years outside academia, working in media
                            companies and a design studio, and later at the Ars Electronica Futurelab, where she
                            collaborated with international partners, including major companies across Europe and Japan,
                            at the intersection of technology, research, and the arts. She is a co-founder of the
                            Initiative Digitalisierung Chancengerecht (IDC), serves on the board of the Austrian
                            Research Promotion Agency (FFG), and has received several honors, including the Vienna
                            Women’s Prize, a Futurezone Award, and the Kaethe Leichter Prize for outstanding
                            contributions to women’s and gender research from the Austrian Federal Ministry for Digital
                            and Economic Affairs. Alongside her teaching and research, she is passionate about science
                            communication, giving public talks, writing commentary, and creating interactive exhibitions
                            on her lab’s topics.
                        </p>
                    </div>
                </div>
            </div>
            <div class="row mb-4">
                <div class="col-xl-3 mb-4" id="talk3">
                    <img src="images/speaker_3.jpg" class="img-speaker shadow" alt="img">
                </div>
                <div class="col-xl-9 mb-4">
                    <h4>Invited Talk III</h4>
                    <h3>From Robot Audition to Ecological AI: Expanding Human-Agent Interaction into the Real World</h3>
                    <div><span>Kazuhiro Nakadai, </span> Institute of Science Tokyo.</div>
                    <div>Link to website: <a
                            href="https://www.ra.sc.e.titech.ac.jp/en/member/kazuhiro-nakadai/">https://www.ra.sc.e.titech.ac.jp/en/member/kazuhiro-nakadai/</a>
                    </div>
                    <div class="speaker-content">
                        <b>Abstract</b>
                        <p>
                            Human-Agent Interaction (HAI) has traditionally centered on dialogue between humans and
                            artificial agents in relatively controlled settings. In this talk, I will present a broader
                            perspective on Ecological AI—agents that adapt not only to humans, but also to the diverse
                            environments in which interaction occurs. The journey begins with robot audition, enabling
                            robots to localize, separate, and understand speech in noisy real-world acoustic scenes. We
                            then extend auditory intelligence to drone audition for disaster response, where agents must
                            support human rescuers under extreme uncertainty. Beyond audition, I will highlight efforts
                            on two-way sign language translation and generation, enabling inclusive communication that
                            bridges spoken and signed languages, and allowing agents to interact naturally with people
                            who rely on sign. Finally, I will turn to wildlife and ecosystem monitoring, where agents
                            listen to and interpret animal vocalizations, connecting humans with the voices of nature.
                            Together, these studies illustrate how HAI can evolve into human–agent–environment
                            interaction, expanding from human-centered conversation to inclusive, resilient, and
                            ecological forms of collaboration.
                        </p>
                        <b>Biography</b>
                        <p>
                            Kazuhiro Nakadai received his B.E., M.E., and Ph.D. degrees in electrical and information
                            engineering from the University of Tokyo in 1993, 1995, and 2003, respectively. He worked at
                            Nippon Telegraph and Telephone (1995–1999), the Kitano Symbiotic Systems Project, ERATO, JST
                            (1999–2003), and Honda Research Institute Japan as a principal scientist (2003–2022). He is
                            currently a professor at the Department of Systems and Control Engineering, Institute of
                            Science Tokyo (formerly Tokyo Institute of Technology). He also held visiting and special
                            appointments at Tokyo Institute of Technology (2006–2022) and served as a guest professor at
                            Waseda University (2011–2018). His research interests include artificial intelligence,
                            robotics, signal processing, computational auditory scene analysis, multimodal integration,
                            and robot audition. He served on the executive boards of the Japanese Society for Artificial
                            Intelligence (2015–2016, 2024–2025) and the Robotics Society of Japan (2017–2018). He is a
                            Fellow of IEEE and RSJ.
                        </p>
                    </div>
                </div>
            </div>
            <div class="row mb-4">
                <div class="col-xl-3 mb-4" id="talk4">
                    <img src="images/speaker_4.jpg" class="img-speaker shadow" alt="img">
                </div>
                <div class="col-xl-9 mb-4">
                    <h4>Invited Talk IV</h4>
                    <h3>The Future of Intimacy: Understanding Artificial Romantic Relationships in a Digital Age</h3>
                    <div><span>Mayu Koike,</span> Institute of Science Tokyo</div>
                    <div>Link to website:
                        <!-- a
                            href="https://researchmap.jp/inamura/?lang=english">https://researchmap.jp/inamura/?lang=english</a-->
                    </div>
                    <div class="speaker-content">
                        <b>Abstract</b>
                        <p>
                            In recent years, AI companions have gained remarkable popularity worldwide. What began as
                            relatively simple chatbots or entertainment applications has rapidly developed into systems
                            that many people now turn to for emotional support, daily conversation, and even romantic
                            companionship. For some individuals, these AI partners are not only a source of comfort but
                            also function as meaningful figures in their personal lives. This development highlights a
                            significant cultural and technological shift: artificial agents are no longer perceived
                            solely as tools, but increasingly as “partners” in human relationships.
                            The growing prevalence of AI companions prompts us to reconsider what it means to form
                            emotional attachments, and how such relationships might influence human-to-human connections
                            in broader society. This workshop presentation will examine these questions by exploring
                            recent findings on the psychology of virtual intimacy of human and virtual agents.
                            These findings highlight the psychological potential of virtual romance and the importance
                            of understanding how emerging technologies are reshaping human relationships.
                        </p>
                        <b>Biography</b>
                        <p>
                            Mayu Koike is an assistant professor at the Institute of Science Tokyo. She obtained her PhD
                            in Psychology from The University of Edinburgh. Her work focuses on the relationships
                            between people and virtual agents. She is particularly interested in how people form strong
                            attachments (love and romantic relationships) with virtual agents, and the potential for
                            improving psychological well-being within this context.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="flash-talks"></a>
                <h4 class="sub-header">Flash talks</h4>
            </div>
            <div id="flash-talk-1" class="poster">
                <div>
                    <span class="sub-time-bg">09:33</span>
                    <span class="sub-ribbon">09:41</span>
                </div>
                <span>Robots with Attitudes: Influence of LLM-Driven Robot Personalities on Motivation and
                    Performance</span>
                <span>Dennis Becker, Kyra Ahrens, Connor Gäde, Erik Strahl, Stefan Wermter</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_1/paper.pdf">PDF</a>
                    <!--a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_1/video.webm">video</a-->
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_1/poster.pdf">poster</a>
                </div>
            </div>
            <div id="flash-talk-2" class="poster">
                <div>
                    <span class="sub-time-bg">09:41</span>
                    <span class="sub-ribbon">09:49</span>
                </div>
                <span>Emotional Coregulation in Close Relationships with AI Agents</span>
                <span>Ethel Pruss, Sascha Struijs, Maryam Alimardani, Sander Koole</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_2/paper.pdf">PDF</a>
                    <!--a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_2/video.webm">video</a-->
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_2/slide.pdf">slide</a>
                    <!--a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_2/poster.pdf">poster</a-->
                </div>
            </div>
            <div id="flash-talk-3" class="poster">
                <div>
                    <span class="sub-time-bg">09:49</span>
                    <span class="sub-ribbon">09:57</span>
                </div>
                <span>Social Buddy or Exercise Coach? Exploring Older Adults’ Preferences for System Personality in
                    Exercise Support</span>
                <span>Rayna Hata; Max Hu; Reid Simmons; Aaron Steinfeld</span>
                <div class="btn-group btn-group-xs" role="group">

                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_3/paper.pdf">PDF</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_3/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_3/poster.pdf">poster</a>
                </div>
            </div>
            <div id="flash-talk-4" class="poster">
                <div>
                    <span class="sub-time-bg">09:57</span>
                    <span class="sub-ribbon">10:05</span>
                </div>
                <span>Driving Like an Experienced, Well-behaved Human Driver: Enhancing Trust in Autonomous Vehicles
                    through Social and Spatial Interactions</span>
                <span>Huaizhuo Yang; Yixiao Wang; Wayne Li; Mengyao Li; Tim Purdy</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_4/paper.pdf">PDF</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_4/video.webm">video</a>
                    <!--a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_4/poster.pdf">poster</a-->
                </div>
            </div>
            <div id="flash-talk-5" class="poster">
                <div>
                    <span class="sub-time-bg">10:05</span>
                    <span class="sub-ribbon">10:13</span>
                </div>
                <span>Multi-Level AI Trustworthiness Labels Scale Potential Users’ Perceptions and Evaluations of AI
                    Products</span>
                <span>Christina. U. Pfeuffer</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_5/paper.pdf">PDF</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_5/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_5/poster.pdf">poster</a>
                </div>
            </div>
            <div id="flash-talk-6" class="poster">
                <div>
                    <span class="sub-time-bg">10:13</span>
                    <span class="sub-ribbon">10:21</span>
                </div>
                <span>Preliminary Prototyping of Avoidance Behaviors Triggered by a User’s Physical Approach to a
                    Robot</span>
                <span>Tomoko Yonezawa; Hirotake Yamazoe; Atsuo Fujino; Daigo Suhara; Takaya Tamamoto; Yuto
                    Nishiguchi</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_6/paper.pdf">PDF</a>
                    <!--a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_6/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_6/poster.pdf">poster</a-->
                </div>
            </div>
            <div id="flash-talk-7" class="poster">
                <div>
                    <span class="sub-time-bg">14:15</span>
                    <span class="sub-ribbon">14:23</span>
                </div>
                <span>Unpacking the Distinct Roles of Mimicry and Synchrony in Emotion Regulation and Bonding: A Virtual
                    Human Interaction Study</span>
                <span>Ethel Pruss; Maryam Alimardani; Sascha Struijs; Sander L. Koole</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_7/paper.pdf">PDF</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_7/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_7/poster.pdf">poster</a>
                </div>
            </div>
            <div id="flash-talk-8" class="poster">
                <div>
                    <span class="sub-time-bg">14:23</span>
                    <span class="sub-ribbon">14:31</span>
                </div>
                <span>Empowering Diverse Health Literacy Needs with Multi-Agent Health Interventions: Design Challenges
                    for Socially Aware Multi-Agent Systems</span>
                <span>Rashi Ghosh; Benjamin Lok</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_8/paper.pdf">PDF</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_8/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_8/poster.pdf">poster</a>
                </div>
            </div>
            <div id="flash-talk-9" class="poster">
                <div>
                    <span class="sub-time-bg">14:31</span>
                    <span class="sub-ribbon">14:39</span>
                </div>
                <span>Unconscious and Intentional Human Cues for Designing Expressive Robot-Arm Motions</span>
                <span>Taito Tashiro; Tomoko Yonezawa; Hirotake Yamazoe</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_9/paper.pdf">PDF</a>
                    <!-- a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_9/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_9/poster.pdf">poster</a-->
                </div>
            </div>
            <div id="flash-talk-10" class="poster">
                <div>
                    <span class="sub-time-bg">14:39</span>
                    <span class="sub-ribbon">14:47</span>
                </div>
                <span>Who Has the Final Say? Conformity Dynamics in ChatGPT’s Selections</span>
                <span>Clarissa Sabrina Arlinghaus; Tristan Kenneweg; Barbara Hammer; Gunter W. Maier</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_10/paper.pdf">PDF</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_10/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_10/poster.pdf">poster</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_10/slide.pdf">slide</a>
                </div>
            </div>
            <div id="flash-talk-11" class="poster">
                <div>
                    <span class="sub-time-bg">14:47</span>
                    <span class="sub-ribbon">14:55</span>
                </div>
                <span>The unempathetic agent: Inducing cognitive change with a Critical Tongue Dialogue Strategy</span>
                <span>Keisuke Magara; Tomoki Miyamoto; Akira Utsumi</span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_11/paper.pdf">PDF</a>
                    <!--a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_11/video.webm">video</a>
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_11/poster.pdf">poster</a-->
                </div>
            </div>
            <div id="flash-talk-12" class="poster">
                <div>
                    <span class="sub-time-bg">14:55</span>
                    <span class="sub-ribbon">15:03</span>
                </div>
                <span>Extended Nonverbal Expressions in Hybrid Robots with Physical and AR-Based Presentations</span>
                <span>Ikkaku Kawaguchi; Keiichi Ihara; Yusuke Ashizawa; Shintaro Mori; Miki Hasegawa; Taito Ishii; Asahi
                    Yamada
                </span>
                <div class="btn-group btn-group-xs" role="group">
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_12/paper.pdf">PDF</a>
                    <!-- a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_12/video.webm">video</a-->
                    <a class="btn" target="_blank" rel="noopener noreferrer"
                        href="./flash_talks/HAI_12/poster.pdf">poster</a>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="motivation"></a>
                <h2 class="h1-bullet">Motivation and Background</h2>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <p style="text-indent: 50px;">This workshop theme centers on the development of AI agents and systems
                    that are capable of understanding, adapting to, and reacting to collaborate with humans in
                    compliance with the social norms. These systems leverage insights from social psychology, cognitive
                    science, robotics, and Al to interpret social cues, anticipate the needs of others, and coordinate
                    actions effectively within dynamic and often unpredictable contexts. We focus on embedding social
                    awareness into AI systems, leading to Cooperative Intelligence which focuses on building trust
                    and relationship between humans and intelligent systems, instead of focusing on functions to replace
                    humans. This paradigm is expected to realize a hybrid society, where humans coexist with ubiquitous
                    intelligent agents.</p>

                <p style="text-indent: 50px;">It is increasingly important for intelligent systems-such as robots,
                    virtual agents, and human-machine interfaces-to collaborate and interact seamlessly with humans
                    across diverse settings, including homes, factories, offices, and transportation systems. Achieving
                    efficient and intelligent humans-system collaboration relies on cooperative intelligence, which
                    draws on interdisciplinary research spanning robotics, AI, human-robot and human-computer
                    interaction, computer vision, and cognitive science.</p>

            </div>
        </div>

        <div class="row">
            <div class="col-xs-12">
                <a class="anchor" id="organizers"></a>
                <h2 class="h1-bullet">Organizers</h2>
            </div>
        </div>
        <div class="row mb-4">
            <div class="col-xl-4 col-md-4 mb-4">
                <div class="organizer-card shadow-sm">
                    <h5 class="card-title">Jouh Yeong Chew</h5>
                    <p class="card-text">Honda Research Institute Japan</p>
                    <a href="mailto:jouhyeong.chew@jp.honda-ri.com">jouhyeong.chew@jp.honda-ri.com</a>
                </div>
            </div>
            <div class="col-xl-4 col-md-4 mb-4">
                <div class="organizer-card shadow-sm">
                    <h5 class="card-title">Alan Sarkisian</h5>
                    <p class="card-text">Honda Research Institute Japan</p>
                    <a href="mailto:alan.sarkisian@jp.honda-ri.com">alan.sarkisian@jp.honda-ri.com</a>
                </div>
            </div>
            <div class="col-xl-4 col-md-4 mb-4">
                <div class="organizer-card shadow-sm">
                    <h5 class="card-title">Christiane Wiebel-Herboth</h5>
                    <p class="card-text">Honda Research Institute Europe</p>
                    <a href="mailto:christiane.wiebel@honda-ri.de">christiane.wiebel@honda-ri.de</a>
                </div>
            </div>
            <div class="col-xl-4 col-md-4 mb-4">
                <div class="organizer-card shadow-sm">
                    <h5 class="card-title">Christiane Attig</h5>
                    <p class="card-text">Honda Research Institute Europe</p>
                    <a href="mailto:christiane.attig@honda-ri.de">christiane.attig@honda-ri.de</a>
                </div>
            </div>
            <div class="col-xl-4 col-md-4 mb-4">
                <div class="organizer-card shadow-sm">
                    <h5 class="card-title">Zhaobo Zheng</h5>
                    <p class="card-text">Honda Research Institute USA</p>
                    <a href="mailto:zhaobo_zheng@honda-ri.com">zhaobo_zheng@honda-ri.com</a>
                </div>
            </div>
            <div class="col-xl-4 col-md-4 mb-4">
                <div class="organizer-card shadow-sm">
                    <h5 class="card-title">Shigeaki Nishina</h5>
                    <p class="card-text">Honda Research Institute Japan</p>
                    <a href="mailto:alan.sarkisian@jp.honda-ri.com">nishina@jp.honda-ri.com</a>
                </div>
            </div>
        </div>
    </div>

    <footer class="d-flex flex-wrap justify-content-between align-items-center py-3 my-4 border-top">
        <div class="col-md-8 d-flex align-items-center">
            <a target="_blank" href="https://www.jp.honda-ri.com/en/"
                class="mb-3 me-2 mb-md-0 text-muted text-decoration-none lh-1">
                <img src="images/logo_hri.png" width="50" height="20">
            </a>
            <span class="mb-3 mb-md-0 text-body-secondary">© 2025 Honda Research Institute Japan</span>
        </div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.min.js"></script>
</body>

</html>